{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on all data V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and preprocessing objects saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the JSON dataset\n",
    "def load_json_dataset(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "file_path = 'my_env/data/train.json'  # Replace with your actual file path for the dataset\n",
    "\n",
    "df = load_json_dataset(file_path)\n",
    "\n",
    "# Encode labels\n",
    "label_map = {label: idx for idx, label in enumerate(df['label'].unique())}\n",
    "df['label'] = df['label'].map(label_map)\n",
    "\n",
    "# Extract features using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['claim']).toarray()\n",
    "y = df['label']\n",
    "\n",
    "# Handle imbalanced data with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Using optimized parameters for RandomForest\n",
    "best_rf = RandomForestClassifier(\n",
    "    max_depth=None,  # Limited depth\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=200,  # Reduced number of trees\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Train the model with the optimized parameters\n",
    "best_rf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Save the model and preprocessing objects\n",
    "with open('all_data_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_rf, model_file)\n",
    "\n",
    "with open('all_data_tfidf_vectorizer.pkl', 'wb') as tfidf_file:\n",
    "    pickle.dump(vectorizer, tfidf_file)\n",
    "\n",
    "with open('all_data_label_map.pkl', 'wb') as label_map_file:\n",
    "    pickle.dump(label_map, label_map_file)\n",
    "\n",
    "print(\"Model and preprocessing objects saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on all data V2\n",
    "removed SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and preprocessing objects saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the JSON dataset\n",
    "def load_json_dataset(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "file_path = 'my_env/data/train.json'  # Replace with your actual file path for the dataset\n",
    "\n",
    "df = load_json_dataset(file_path)\n",
    "\n",
    "# Encode labels\n",
    "label_map = {label: idx for idx, label in enumerate(df['label'].unique())}\n",
    "df['label'] = df['label'].map(label_map)\n",
    "\n",
    "# Extract features using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['claim']).toarray()\n",
    "y = df['label']\n",
    "\n",
    "# Handle imbalanced data with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Using optimized parameters for RandomForest\n",
    "best_rf = RandomForestClassifier(\n",
    "    max_depth=None,  # Limited depth\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=200,  # Reduced number of trees\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Train the model with the optimized parameters\n",
    "best_rf.fit(X, y)\n",
    "\n",
    "# Save the model and preprocessing objects\n",
    "version = \"V2\"\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_model_{version}.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_rf, model_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_tfidf_vectorizer_{version}.pkl', 'wb') as tfidf_file:\n",
    "    pickle.dump(vectorizer, tfidf_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_label_map_{version}.pkl', 'wb') as label_map_file:\n",
    "    pickle.dump(label_map, label_map_file)\n",
    "\n",
    "print(\"Model and preprocessing objects saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trained on NEE / CP V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the JSON dataset\n",
    "def load_json_dataset(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "file_path = 'my_env/data/nee_cp_from_train.json'  # Replace with your actual file path for the dataset\n",
    "\n",
    "df = load_json_dataset(file_path)\n",
    "\n",
    "# Encode labels\n",
    "label_map = {label: idx for idx, label in enumerate(df['label'].unique())}\n",
    "df['label'] = df['label'].map(label_map)\n",
    "\n",
    "# Extract features using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['claim']).toarray()\n",
    "y = df['label']\n",
    "\n",
    "# Handle imbalanced data with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Using optimized parameters for RandomForest\n",
    "best_rf = RandomForestClassifier(\n",
    "    max_depth=None,  # Limited depth\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=200,  # Reduced number of trees\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Train the model with the optimized parameters\n",
    "best_rf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Save the model and preprocessing objects\n",
    "version = \"\"\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cp_model_{version}.pkl', 'wb') as secondary_model_file:\n",
    "    pickle.dump(best_rf, secondary_model_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cptfidf_vectorizer_{version}.pkl', 'wb') as secondary_tfidf_file:\n",
    "    pickle.dump(vectorizer, secondary_tfidf_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cplabel_map_{version}.pkl', 'wb') as secondary_label_map_file:\n",
    "    pickle.dump(label_map, secondary_label_map_file)\n",
    "\n",
    "print(\"Model and preprocessing objects saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trained on NEE / CP V2\n",
    "remove SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the JSON dataset\n",
    "def load_json_dataset(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "file_path = 'my_env/data/nee_cp_from_train.json'  # Replace with your actual file path for the dataset\n",
    "\n",
    "df = load_json_dataset(file_path)\n",
    "\n",
    "# Encode labels\n",
    "label_map = {label: idx for idx, label in enumerate(df['label'].unique())}\n",
    "df['label'] = df['label'].map(label_map)\n",
    "\n",
    "# Extract features using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['claim']).toarray()\n",
    "y = df['label']\n",
    "\n",
    "# Handle imbalanced data with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Using optimized parameters for RandomForest\n",
    "best_rf = RandomForestClassifier(\n",
    "    max_depth=None,  # Limited depth\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=200,  # Reduced number of trees\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Train the model with the optimized parameters\n",
    "best_rf.fit(X, y)\n",
    "\n",
    "# Save the model and preprocessing objects\n",
    "version = \"V2\"\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cp_model_{version}.pkl', 'wb') as secondary_model_file:\n",
    "    pickle.dump(best_rf, secondary_model_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cptfidf_vectorizer_{version}.pkl', 'wb') as secondary_tfidf_file:\n",
    "    pickle.dump(vectorizer, secondary_tfidf_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cplabel_map_{version}.pkl', 'wb') as secondary_label_map_file:\n",
    "    pickle.dump(label_map, secondary_label_map_file)\n",
    "\n",
    "print(\"Model and preprocessing objects saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification & Accuracy Report *not accurate\n",
    "\n",
    "accuracy report is weird, switch to new method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                         Supported       0.92      0.09      0.16       122\n",
      "                           Refuted       0.68      0.60      0.64       305\n",
      "Conflicting Evidence/Cherrypicking       0.18      0.39      0.24        38\n",
      "               Not Enough Evidence       0.18      0.69      0.28        35\n",
      "\n",
      "                          accuracy                           0.47       500\n",
      "                         macro avg       0.49      0.44      0.33       500\n",
      "                      weighted avg       0.67      0.47      0.47       500\n",
      "\n",
      "Accuracy for 'Supported': 0.09\n",
      "Accuracy for 'Refuted': 0.60\n",
      "Accuracy for 'Conflicting Evidence/Cherrypicking': 0.09\n",
      "Accuracy for 'Not Enough Evidence': 0.60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Load the main model and preprocessing objects\n",
    "with open('all_data_model.pkl', 'rb') as model_file:\n",
    "    main_rf = pickle.load(model_file)\n",
    "\n",
    "with open('all_data_tfidf_vectorizer.pkl', 'rb') as tfidf_file:\n",
    "    main_vectorizer = pickle.load(tfidf_file)\n",
    "\n",
    "with open('all_data_label_map.pkl', 'rb') as label_map_file:\n",
    "    main_label_map = pickle.load(label_map_file)\n",
    "\n",
    "# Load the secondary model and preprocessing objects\n",
    "with open('nee_cp_model.pkl', 'rb') as secondary_model_file:\n",
    "    secondary_rf = pickle.load(secondary_model_file)\n",
    "\n",
    "with open('nee_cptfidf_vectorizer.pkl', 'rb') as secondary_tfidf_file:\n",
    "    secondary_vectorizer = pickle.load(secondary_tfidf_file)\n",
    "\n",
    "with open('nee_cplabel_map.pkl', 'rb') as secondary_label_map_file:\n",
    "    secondary_label_map = pickle.load(secondary_label_map_file)\n",
    "\n",
    "# Inverse label maps\n",
    "main_label_map_inverse = {v: k for k, v in main_label_map.items()}\n",
    "secondary_label_map_inverse = {v: k for k, v in secondary_label_map.items()}\n",
    "\n",
    "# Preprocess claims using the respective vectorizers\n",
    "def preprocess_claim(claim, vectorizer):\n",
    "    return vectorizer.transform([claim]).toarray()\n",
    "\n",
    "# First step: Classify claims using the main model\n",
    "def classify_main(claim):\n",
    "    features = preprocess_claim(claim, main_vectorizer)\n",
    "    prediction = main_rf.predict(features)\n",
    "    probability_distribution = main_rf.predict_proba(features)\n",
    "    confidence = np.max(probability_distribution)\n",
    "    return prediction[0], confidence\n",
    "\n",
    "# Second step: Classify claims using the secondary model\n",
    "def classify_secondary(claim):\n",
    "    features = preprocess_claim(claim, secondary_vectorizer)\n",
    "    prediction = secondary_rf.predict(features)\n",
    "    return prediction[0]\n",
    "\n",
    "# Load the JSON dataset\n",
    "def load_json_dataset(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate accuracy per label\n",
    "def calculate_combined_accuracy(df):\n",
    "    correct_predictions = {label: 0 for label in main_label_map.values()}\n",
    "    correct_predictions.update({label: 0 for label in secondary_label_map.values()})\n",
    "    total_predictions = {label: 0 for label in main_label_map.values()}\n",
    "    total_predictions.update({label: 0 for label in secondary_label_map.values()})\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        claim = row['claim']\n",
    "        actual_label = row['label']\n",
    "        predicted_label, confidence = classify_main(claim)\n",
    "        \n",
    "        if main_label_map_inverse[predicted_label] in ['Supported', 'Refuted'] and confidence >= 0.60:\n",
    "            y_true.append(actual_label)\n",
    "            y_pred.append(predicted_label)\n",
    "            total_predictions[actual_label] += 1\n",
    "            if predicted_label == actual_label:\n",
    "                correct_predictions[actual_label] += 1\n",
    "        else:\n",
    "            secondary_predicted_label = classify_secondary(claim)\n",
    "            # Ensure the secondary predicted label is mapped correctly\n",
    "            secondary_predicted_label_mapped = list(main_label_map.values()).index(secondary_predicted_label + 2)\n",
    "            y_true.append(actual_label)\n",
    "            y_pred.append(secondary_predicted_label_mapped)\n",
    "            total_predictions[actual_label] += 1\n",
    "            if secondary_predicted_label_mapped == actual_label:\n",
    "                correct_predictions[actual_label] += 1\n",
    "    \n",
    "    labels = list(main_label_map.values())[:2] + [v + 2 for v in secondary_label_map.values()]\n",
    "    target_names = list(main_label_map_inverse.values())[:2] + list(secondary_label_map_inverse.values())\n",
    "    \n",
    "    accuracy_per_label = classification_report(y_true, y_pred, labels=labels, target_names=target_names)\n",
    "    \n",
    "    accuracy_dict = {main_label_map_inverse[label]: correct_predictions[label] / total_predictions[label] if total_predictions[label] > 0 else 0 for label in main_label_map.values()}\n",
    "    accuracy_dict.update({secondary_label_map_inverse[label]: correct_predictions[label] / total_predictions[label] if total_predictions[label] > 0 else 0 for label in secondary_label_map.values()})\n",
    "    \n",
    "    return accuracy_per_label, accuracy_dict\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "file_path = 'my_env/data/dev.json'  # Replace with your actual file path for the dataset\n",
    "df = load_json_dataset(file_path)\n",
    "\n",
    "# Encode labels in the dataframe\n",
    "df['label'] = df['label'].map(main_label_map).fillna(df['label'].map(secondary_label_map))\n",
    "\n",
    "# Calculate combined accuracy per label\n",
    "combined_accuracy_per_label, accuracy_dict = calculate_combined_accuracy(df)\n",
    "\n",
    "# Display the results\n",
    "print(combined_accuracy_per_label)\n",
    "for label, accuracy in accuracy_dict.items():\n",
    "    print(f\"Accuracy for '{label}': {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both Models on Dev set V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the main model and preprocessing objects\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_model.pkl', 'rb') as model_file:\n",
    "    main_rf = pickle.load(model_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_tfidf_vectorizer.pkl', 'rb') as tfidf_file:\n",
    "    main_vectorizer = pickle.load(tfidf_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_label_map.pkl', 'rb') as label_map_file:\n",
    "    main_label_map = pickle.load(label_map_file)\n",
    "\n",
    "# Load the secondary model and preprocessing objects\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cp_model.pkl', 'rb') as secondary_model_file:\n",
    "    secondary_rf = pickle.load(secondary_model_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cptfidf_vectorizer.pkl', 'rb') as secondary_tfidf_file:\n",
    "    secondary_vectorizer = pickle.load(secondary_tfidf_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cplabel_map.pkl', 'rb') as secondary_label_map_file:\n",
    "    secondary_label_map = pickle.load(secondary_label_map_file)\n",
    "\n",
    "# Inverse label maps\n",
    "main_label_map_inverse = {v: k for k, v in main_label_map.items()}\n",
    "secondary_label_map_inverse = {v: k for k, v in secondary_label_map.items()}\n",
    "\n",
    "# Preprocess claims using the respective vectorizers\n",
    "def preprocess_claim(claim, vectorizer):\n",
    "    return vectorizer.transform([claim]).toarray()\n",
    "\n",
    "# First step: Classify claims using the main model\n",
    "def classify_main(claim):\n",
    "    features = preprocess_claim(claim, main_vectorizer)\n",
    "    prediction = main_rf.predict(features)\n",
    "    probability_distribution = main_rf.predict_proba(features)\n",
    "    confidence = np.max(probability_distribution)\n",
    "    return prediction[0], confidence, probability_distribution[0]\n",
    "\n",
    "# Second step: Classify claims using the secondary model\n",
    "def classify_secondary(claim):\n",
    "    features = preprocess_claim(claim, secondary_vectorizer)\n",
    "    prediction = secondary_rf.predict(features)\n",
    "    probability_distribution = secondary_rf.predict_proba(features)\n",
    "    return prediction[0], probability_distribution[0]\n",
    "\n",
    "# Two-step classification process for a single claim\n",
    "def predict_single_claim(claim):\n",
    "    predicted_label, confidence, probability_distribution = classify_main(claim)\n",
    "    \n",
    "    if main_label_map_inverse[predicted_label] in ['Supported', 'Refuted'] and confidence >= 0.75:\n",
    "        # High confidence in main model's prediction\n",
    "        predicted_label_name = main_label_map_inverse[predicted_label]\n",
    "        class_probabilities = {main_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "    else:\n",
    "        # Use secondary model for further classification\n",
    "        predicted_label, probability_distribution = classify_secondary(claim)\n",
    "        predicted_label_name = secondary_label_map_inverse[predicted_label]\n",
    "        class_probabilities = {secondary_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "\n",
    "    return predicted_label_name, class_probabilities\n",
    "\n",
    "# Function to iterate through the dataset and predict labels\n",
    "def predict_dataset(file_path, output_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_json(file_path)\n",
    "\n",
    "    # Initialize results list\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each claim in the dataset\n",
    "    for index, row in df.iterrows():\n",
    "        claim = row['claim']\n",
    "        actual_label = row['label']\n",
    "        predicted_label, class_probabilities = predict_single_claim(claim)\n",
    "        result = {\n",
    "            'claim': claim,\n",
    "            'actual_label': actual_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'class_probabilities': class_probabilities\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Write the results to a new JSON file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(results, outfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'my_env/data/dev.json'  # Replace with your actual file path\n",
    "\n",
    "json_output_filename = \"predicted_claims_both_models\"\n",
    "output_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'\n",
    "predict_dataset(input_file_path, output_file_path)\n",
    "print(f\"Predicted labels written to {output_file_path}\")\n",
    "\n",
    "\n",
    "## check accuracies\n",
    "\n",
    "import json\n",
    "\n",
    "# Function to calculate accuracy per label\n",
    "def calculate_accuracy_from_json(input_file):\n",
    "    # Load the results from the JSON file\n",
    "    with open(input_file, 'r') as file:\n",
    "        results = json.load(file)\n",
    "    \n",
    "    # Initialize counters for correct predictions and total predictions per label\n",
    "    correct_predictions = {}\n",
    "    total_predictions = {}\n",
    "    \n",
    "    # Iterate through the results and update counters\n",
    "    for result in results:\n",
    "        actual_label = result['actual_label']\n",
    "        predicted_label = result['predicted_label']\n",
    "        \n",
    "        if actual_label not in correct_predictions:\n",
    "            correct_predictions[actual_label] = 0\n",
    "            total_predictions[actual_label] = 0\n",
    "            \n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions[actual_label] += 1\n",
    "        \n",
    "        total_predictions[actual_label] += 1\n",
    "    \n",
    "    # Calculate accuracy per label\n",
    "    accuracy_per_label = {label: correct_predictions[label] / total_predictions[label] \n",
    "                          for label in total_predictions}\n",
    "    \n",
    "    return accuracy_per_label\n",
    "\n",
    "# Example usage\n",
    "input_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'\n",
    "accuracy_per_label = calculate_accuracy_from_json(input_file_path)\n",
    "\n",
    "# Display the results\n",
    "for label, accuracy in accuracy_per_label.items():\n",
    "    print(f\"Accuracy for '{label}': {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both Models on Dev set V2\n",
    "\n",
    "smote removed from both models, no other changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels written to my_env/tf-idf_data_and_models/json_outputs/predicted_claims_both_models_V2.json\n",
      "Accuracy for 'Refuted': 0.46\n",
      "Accuracy for 'Supported': 0.11\n",
      "Accuracy for 'Not Enough Evidence': 0.80\n",
      "Accuracy for 'Conflicting Evidence/Cherrypicking': 0.39\n"
     ]
    }
   ],
   "source": [
    "version = '_V2'\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the main model and preprocessing objects\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_model{version}.pkl', 'rb') as model_file:\n",
    "    main_rf = pickle.load(model_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_tfidf_vectorizer{version}.pkl', 'rb') as tfidf_file:\n",
    "    main_vectorizer = pickle.load(tfidf_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_label_map{version}.pkl', 'rb') as label_map_file:\n",
    "    main_label_map = pickle.load(label_map_file)\n",
    "\n",
    "# Load the secondary model and preprocessing objects\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cp_model{version}.pkl', 'rb') as secondary_model_file:\n",
    "    secondary_rf = pickle.load(secondary_model_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cptfidf_vectorizer{version}.pkl', 'rb') as secondary_tfidf_file:\n",
    "    secondary_vectorizer = pickle.load(secondary_tfidf_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cplabel_map{version}.pkl', 'rb') as secondary_label_map_file:\n",
    "    secondary_label_map = pickle.load(secondary_label_map_file)\n",
    "\n",
    "# Inverse label maps\n",
    "main_label_map_inverse = {v: k for k, v in main_label_map.items()}\n",
    "secondary_label_map_inverse = {v: k for k, v in secondary_label_map.items()}\n",
    "\n",
    "# Preprocess claims using the respective vectorizers\n",
    "def preprocess_claim(claim, vectorizer):\n",
    "    return vectorizer.transform([claim]).toarray()\n",
    "\n",
    "# First step: Classify claims using the main model\n",
    "def classify_main(claim):\n",
    "    features = preprocess_claim(claim, main_vectorizer)\n",
    "    prediction = main_rf.predict(features)\n",
    "    probability_distribution = main_rf.predict_proba(features)\n",
    "    confidence = np.max(probability_distribution)\n",
    "    return prediction[0], confidence, probability_distribution[0]\n",
    "\n",
    "# Second step: Classify claims using the secondary model\n",
    "def classify_secondary(claim):\n",
    "    features = preprocess_claim(claim, secondary_vectorizer)\n",
    "    prediction = secondary_rf.predict(features)\n",
    "    probability_distribution = secondary_rf.predict_proba(features)\n",
    "    return prediction[0], probability_distribution[0]\n",
    "\n",
    "# Two-step classification process for a single claim\n",
    "def predict_single_claim(claim):\n",
    "    predicted_label, confidence, probability_distribution = classify_main(claim)\n",
    "    \n",
    "    if main_label_map_inverse[predicted_label] in ['Supported', 'Refuted'] and confidence >= 0.65:\n",
    "        # High confidence in main model's prediction\n",
    "        predicted_label_name = main_label_map_inverse[predicted_label]\n",
    "        class_probabilities = {main_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "    else:\n",
    "        # Use secondary model for further classification\n",
    "        predicted_label, probability_distribution = classify_secondary(claim)\n",
    "        predicted_label_name = secondary_label_map_inverse[predicted_label]\n",
    "        class_probabilities = {secondary_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "\n",
    "    return predicted_label_name, class_probabilities\n",
    "\n",
    "# Function to iterate through the dataset and predict labels\n",
    "def predict_dataset(file_path, output_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_json(file_path)\n",
    "\n",
    "    # Initialize results list\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each claim in the dataset\n",
    "    for index, row in df.iterrows():\n",
    "        claim = row['claim']\n",
    "        actual_label = row['label']\n",
    "        predicted_label, class_probabilities = predict_single_claim(claim)\n",
    "        result = {\n",
    "            'claim': claim,\n",
    "            'actual_label': actual_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'confidence': confidence,\n",
    "            'class_probabilities': class_probabilities\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Write the results to a new JSON file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(results, outfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'my_env/data/dev.json'  # Replace with your actual file path\n",
    "\n",
    "json_output_filename = f\"predicted_claims_both_models{version}\"\n",
    "output_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'\n",
    "predict_dataset(input_file_path, output_file_path)\n",
    "print(f\"Predicted labels written to {output_file_path}\")\n",
    "\n",
    "\n",
    "## check accuracies\n",
    "\n",
    "import json\n",
    "\n",
    "# Function to calculate accuracy per label\n",
    "def calculate_accuracy_from_json(input_file):\n",
    "    # Load the results from the JSON file\n",
    "    with open(input_file, 'r') as file:\n",
    "        results = json.load(file)\n",
    "    \n",
    "    # Initialize counters for correct predictions and total predictions per label\n",
    "    correct_predictions = {}\n",
    "    total_predictions = {}\n",
    "    \n",
    "    # Iterate through the results and update counters\n",
    "    for result in results:\n",
    "        actual_label = result['actual_label']\n",
    "        predicted_label = result['predicted_label']\n",
    "        \n",
    "        if actual_label not in correct_predictions:\n",
    "            correct_predictions[actual_label] = 0\n",
    "            total_predictions[actual_label] = 0\n",
    "            \n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions[actual_label] += 1\n",
    "        \n",
    "        total_predictions[actual_label] += 1\n",
    "    \n",
    "    # Calculate accuracy per label\n",
    "    accuracy_per_label = {label: correct_predictions[label] / total_predictions[label] \n",
    "                          for label in total_predictions}\n",
    "    \n",
    "    return accuracy_per_label\n",
    "\n",
    "# Example usage\n",
    "input_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'\n",
    "accuracy_per_label = calculate_accuracy_from_json(input_file_path)\n",
    "\n",
    "# Display the results\n",
    "for label, accuracy in accuracy_per_label.items():\n",
    "    print(f\"Accuracy for '{label}': {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both Models on just Not enough evidence & conflicting evidence V1\n",
    "## * *insanity check* *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels written to my_env/tf-idf_data_and_models/json_outputs/predicted_claims_both_models_just_nee_cp_claims.json\n",
      "Accuracy for 'Not Enough Evidence': 0.74\n",
      "Accuracy for 'Conflicting Evidence/Cherrypicking': 0.42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the main model and preprocessing objects\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_model.pkl', 'rb') as model_file:\n",
    "    main_rf = pickle.load(model_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_tfidf_vectorizer.pkl', 'rb') as tfidf_file:\n",
    "    main_vectorizer = pickle.load(tfidf_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_label_map.pkl', 'rb') as label_map_file:\n",
    "    main_label_map = pickle.load(label_map_file)\n",
    "\n",
    "# Load the secondary model and preprocessing objects\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cp_model.pkl', 'rb') as secondary_model_file:\n",
    "    secondary_rf = pickle.load(secondary_model_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cptfidf_vectorizer.pkl', 'rb') as secondary_tfidf_file:\n",
    "    secondary_vectorizer = pickle.load(secondary_tfidf_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cplabel_map.pkl', 'rb') as secondary_label_map_file:\n",
    "    secondary_label_map = pickle.load(secondary_label_map_file)\n",
    "\n",
    "# Inverse label maps\n",
    "main_label_map_inverse = {v: k for k, v in main_label_map.items()}\n",
    "secondary_label_map_inverse = {v: k for k, v in secondary_label_map.items()}\n",
    "\n",
    "# Preprocess claims using the respective vectorizers\n",
    "def preprocess_claim(claim, vectorizer):\n",
    "    return vectorizer.transform([claim]).toarray()\n",
    "\n",
    "# First step: Classify claims using the main model\n",
    "def classify_main(claim):\n",
    "    features = preprocess_claim(claim, main_vectorizer)\n",
    "    prediction = main_rf.predict(features)\n",
    "    probability_distribution = main_rf.predict_proba(features)\n",
    "    confidence = np.max(probability_distribution)\n",
    "    return prediction[0], confidence, probability_distribution[0]\n",
    "\n",
    "# Second step: Classify claims using the secondary model\n",
    "def classify_secondary(claim):\n",
    "    features = preprocess_claim(claim, secondary_vectorizer)\n",
    "    prediction = secondary_rf.predict(features)\n",
    "    probability_distribution = secondary_rf.predict_proba(features)\n",
    "    return prediction[0], probability_distribution[0]\n",
    "\n",
    "# Two-step classification process for a single claim\n",
    "def predict_single_claim(claim):\n",
    "    predicted_label, confidence, probability_distribution = classify_main(claim)\n",
    "    \n",
    "    if main_label_map_inverse[predicted_label] in ['Supported', 'Refuted'] and confidence >= 0.7:\n",
    "        # High confidence in main model's prediction\n",
    "        predicted_label_name = main_label_map_inverse[predicted_label]\n",
    "        class_probabilities = {main_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "    else:\n",
    "        # Use secondary model for further classification\n",
    "        predicted_label, probability_distribution = classify_secondary(claim)\n",
    "        predicted_label_name = secondary_label_map_inverse[predicted_label]\n",
    "        class_probabilities = {secondary_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "\n",
    "    return predicted_label_name, class_probabilities\n",
    "\n",
    "# Function to iterate through the dataset and predict labels\n",
    "def predict_dataset(file_path, output_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_json(file_path)\n",
    "\n",
    "    # Initialize results list\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each claim in the dataset\n",
    "    for index, row in df.iterrows():\n",
    "        claim = row['claim']\n",
    "        actual_label = row['label']\n",
    "        predicted_label, class_probabilities = predict_single_claim(claim)\n",
    "        result = {\n",
    "            'claim': claim,\n",
    "            'actual_label': actual_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'class_probabilities': class_probabilities\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Write the results to a new JSON file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(results, outfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'my_env/data/not_enough_info_from_dev.json'  # Replace with your actual file path\n",
    "\n",
    "json_output_filename = \"predicted_claims_both_models_just_nee_cp_claims\"\n",
    "output_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'\n",
    "predict_dataset(input_file_path, output_file_path)\n",
    "print(f\"Predicted labels written to {output_file_path}\")\n",
    "\n",
    "\n",
    "## check accuracies\n",
    "\n",
    "import json\n",
    "\n",
    "# Function to calculate accuracy per label\n",
    "def calculate_accuracy_from_json(input_file):\n",
    "    # Load the results from the JSON file\n",
    "    with open(input_file, 'r') as file:\n",
    "        results = json.load(file)\n",
    "    \n",
    "    # Initialize counters for correct predictions and total predictions per label\n",
    "    correct_predictions = {}\n",
    "    total_predictions = {}\n",
    "    \n",
    "    # Iterate through the results and update counters\n",
    "    for result in results:\n",
    "        actual_label = result['actual_label']\n",
    "        predicted_label = result['predicted_label']\n",
    "        \n",
    "        if actual_label not in correct_predictions:\n",
    "            correct_predictions[actual_label] = 0\n",
    "            total_predictions[actual_label] = 0\n",
    "            \n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions[actual_label] += 1\n",
    "        \n",
    "        total_predictions[actual_label] += 1\n",
    "    \n",
    "    # Calculate accuracy per label\n",
    "    accuracy_per_label = {label: correct_predictions[label] / total_predictions[label] \n",
    "                          for label in total_predictions}\n",
    "    \n",
    "    return accuracy_per_label\n",
    "\n",
    "# Example usage\n",
    "input_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'\n",
    "accuracy_per_label = calculate_accuracy_from_json(input_file_path)\n",
    "\n",
    "# Display the results\n",
    "for label, accuracy in accuracy_per_label.items():\n",
    "    print(f\"Accuracy for '{label}': {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just Primary Model on dev_data V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels written to my_env/json_outputs/predicted_claims_primary_model.json\n",
      "Accuracy for 'Refuted': 0.98\n",
      "Accuracy for 'Supported': 0.24\n",
      "Accuracy for 'Not Enough Evidence': 0.11\n",
      "Accuracy for 'Conflicting Evidence/Cherrypicking': 0.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the main model and preprocessing objects\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_model.pkl', 'rb') as model_file:\n",
    "    main_rf = pickle.load(model_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_tfidf_vectorizer.pkl', 'rb') as tfidf_file:\n",
    "    main_vectorizer = pickle.load(tfidf_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_label_map.pkl', 'rb') as label_map_file:\n",
    "    main_label_map = pickle.load(label_map_file)\n",
    "\n",
    "# Load the secondary model and preprocessing objects\n",
    "#with open('nee_cp_model.pkl', 'rb') as secondary_model_file:\n",
    "    #secondary_rf = pickle.load(secondary_model_file)\n",
    "\n",
    "#with open('nee_cptfidf_vectorizer.pkl', 'rb') as secondary_tfidf_file:\n",
    "    #secondary_vectorizer = pickle.load(secondary_tfidf_file)\n",
    "\n",
    "#with open('nee_cplabel_map.pkl', 'rb') as secondary_label_map_file:\n",
    "    #secondary_label_map = pickle.load(secondary_label_map_file)\n",
    "\n",
    "# Inverse label maps\n",
    "main_label_map_inverse = {v: k for k, v in main_label_map.items()}\n",
    "#secondary_label_map_inverse = {v: k for k, v in secondary_label_map.items()}\n",
    "\n",
    "# Preprocess claims using the respective vectorizers\n",
    "def preprocess_claim(claim, vectorizer):\n",
    "    return vectorizer.transform([claim]).toarray()\n",
    "\n",
    "# First step: Classify claims using the main model\n",
    "def classify_main(claim):\n",
    "    features = preprocess_claim(claim, main_vectorizer)\n",
    "    prediction = main_rf.predict(features)\n",
    "    probability_distribution = main_rf.predict_proba(features)\n",
    "    confidence = np.max(probability_distribution)\n",
    "    return prediction[0], confidence, probability_distribution[0]\n",
    "\n",
    "# Second step: Classify claims using the secondary model\n",
    "#def classify_secondary(claim):\n",
    "    features = preprocess_claim(claim, secondary_vectorizer)\n",
    "    prediction = secondary_rf.predict(features)\n",
    "    probability_distribution = secondary_rf.predict_proba(features)\n",
    "    return prediction[0], probability_distribution[0]\n",
    "\n",
    "# Two-step classification process for a single claim\n",
    "def predict_single_claim(claim):\n",
    "    predicted_label, confidence, probability_distribution = classify_main(claim)\n",
    "    \n",
    "    #main_label_map_inverse[predicted_label] in ['Supported', 'Refuted'] and confidence >= 0.7:\n",
    "        # High confidence in main model's prediction\n",
    "    predicted_label_name = main_label_map_inverse[predicted_label]\n",
    "    class_probabilities = {main_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "    #else:\n",
    "        # Use secondary model for further classification\n",
    "       # predicted_label, probability_distribution = classify_secondary(claim)\n",
    "       # predicted_label_name = secondary_label_map_inverse[predicted_label]\n",
    "       # class_probabilities = {secondary_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "\n",
    "    return predicted_label_name, class_probabilities\n",
    "\n",
    "# Function to iterate through the dataset and predict labels\n",
    "def predict_dataset(file_path, output_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_json(file_path)\n",
    "\n",
    "    # Initialize results list\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each claim in the dataset\n",
    "    for index, row in df.iterrows():\n",
    "        claim = row['claim']\n",
    "        actual_label = row['label']\n",
    "        predicted_label, class_probabilities = predict_single_claim(claim)\n",
    "        result = {\n",
    "            'claim': claim,\n",
    "            'actual_label': actual_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'class_probabilities': class_probabilities\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Write the results to a new JSON file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(results, outfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "json_output_filename = \"predicted_claims_primary_model_V1\"\n",
    "input_file_path = 'my_env/data/dev.json'  # Replace with your actual file path\n",
    "output_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'\n",
    "predict_dataset(input_file_path, output_file_path)\n",
    "print(f\"Predicted labels written to {output_file_path}\")\n",
    "\n",
    "\n",
    "## check accuracies\n",
    "\n",
    "import json\n",
    "\n",
    "# Function to calculate accuracy per label\n",
    "def calculate_accuracy_from_json(input_file):\n",
    "    # Load the results from the JSON file\n",
    "    with open(input_file, 'r') as file:\n",
    "        results = json.load(file)\n",
    "    \n",
    "    # Initialize counters for correct predictions and total predictions per label\n",
    "    correct_predictions = {}\n",
    "    total_predictions = {}\n",
    "    \n",
    "    # Iterate through the results and update counters\n",
    "    for result in results:\n",
    "        actual_label = result['actual_label']\n",
    "        predicted_label = result['predicted_label']\n",
    "        \n",
    "        if actual_label not in correct_predictions:\n",
    "            correct_predictions[actual_label] = 0\n",
    "            total_predictions[actual_label] = 0\n",
    "            \n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions[actual_label] += 1\n",
    "        \n",
    "        total_predictions[actual_label] += 1\n",
    "    \n",
    "    # Calculate accuracy per label\n",
    "    accuracy_per_label = {label: correct_predictions[label] / total_predictions[label] \n",
    "                          for label in total_predictions}\n",
    "    \n",
    "    return accuracy_per_label\n",
    "\n",
    "# Example usage\n",
    "input_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'   # The JSON file from the previous step\n",
    "accuracy_per_label = calculate_accuracy_from_json(input_file_path)\n",
    "\n",
    "# Display the results\n",
    "for label, accuracy in accuracy_per_label.items():\n",
    "    print(f\"Accuracy for '{label}': {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just Primary Model on dev_data V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels written to my_env/tf-idf_data_and_models/json_outputs/predicted_claims_primary_modelV2.json\n",
      "Accuracy for 'Refuted': 0.98\n",
      "Accuracy for 'Supported': 0.23\n",
      "Accuracy for 'Not Enough Evidence': 0.09\n",
      "Accuracy for 'Conflicting Evidence/Cherrypicking': 0.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the main model and preprocessing objects\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_model_V2.pkl', 'rb') as model_file:\n",
    "    main_rf = pickle.load(model_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_tfidf_vectorizer_V2.pkl', 'rb') as tfidf_file:\n",
    "    main_vectorizer = pickle.load(tfidf_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/all_data_label_map_V2.pkl', 'rb') as label_map_file:\n",
    "    main_label_map = pickle.load(label_map_file)\n",
    "\n",
    "# Load the secondary model and preprocessing objects\n",
    "#with open('nee_cp_model.pkl', 'rb') as secondary_model_file:\n",
    "    #secondary_rf = pickle.load(secondary_model_file)\n",
    "\n",
    "#with open('nee_cptfidf_vectorizer.pkl', 'rb') as secondary_tfidf_file:\n",
    "    #secondary_vectorizer = pickle.load(secondary_tfidf_file)\n",
    "\n",
    "#with open('nee_cplabel_map.pkl', 'rb') as secondary_label_map_file:\n",
    "    #secondary_label_map = pickle.load(secondary_label_map_file)\n",
    "\n",
    "# Inverse label maps\n",
    "main_label_map_inverse = {v: k for k, v in main_label_map.items()}\n",
    "#secondary_label_map_inverse = {v: k for k, v in secondary_label_map.items()}\n",
    "\n",
    "# Preprocess claims using the respective vectorizers\n",
    "def preprocess_claim(claim, vectorizer):\n",
    "    return vectorizer.transform([claim]).toarray()\n",
    "\n",
    "# First step: Classify claims using the main model\n",
    "def classify_main(claim):\n",
    "    features = preprocess_claim(claim, main_vectorizer)\n",
    "    prediction = main_rf.predict(features)\n",
    "    probability_distribution = main_rf.predict_proba(features)\n",
    "    confidence = np.max(probability_distribution)\n",
    "    return prediction[0], confidence, probability_distribution[0]\n",
    "\n",
    "# Second step: Classify claims using the secondary model\n",
    "#def classify_secondary(claim):\n",
    "    features = preprocess_claim(claim, secondary_vectorizer)\n",
    "    prediction = secondary_rf.predict(features)\n",
    "    probability_distribution = secondary_rf.predict_proba(features)\n",
    "    return prediction[0], probability_distribution[0]\n",
    "\n",
    "# Two-step classification process for a single claim\n",
    "def predict_single_claim(claim):\n",
    "    predicted_label, confidence, probability_distribution = classify_main(claim)\n",
    "    \n",
    "    #main_label_map_inverse[predicted_label] in ['Supported', 'Refuted'] and confidence >= 0.7:\n",
    "        # High confidence in main model's prediction\n",
    "    predicted_label_name = main_label_map_inverse[predicted_label]\n",
    "    class_probabilities = {main_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "    #else:\n",
    "        # Use secondary model for further classification\n",
    "       # predicted_label, probability_distribution = classify_secondary(claim)\n",
    "       # predicted_label_name = secondary_label_map_inverse[predicted_label]\n",
    "       # class_probabilities = {secondary_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "\n",
    "    return predicted_label_name, class_probabilities\n",
    "\n",
    "# Function to iterate through the dataset and predict labels\n",
    "def predict_dataset(file_path, output_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_json(file_path)\n",
    "\n",
    "    # Initialize results list\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each claim in the dataset\n",
    "    for index, row in df.iterrows():\n",
    "        claim = row['claim']\n",
    "        actual_label = row['label']\n",
    "        predicted_label, class_probabilities = predict_single_claim(claim)\n",
    "        result = {\n",
    "            'claim': claim,\n",
    "            'actual_label': actual_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'class_probabilities': class_probabilities\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Write the results to a new JSON file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(results, outfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "json_output_filename = \"predicted_claims_primary_modelV2\"\n",
    "input_file_path = 'my_env/data/dev.json'  # Replace with your actual file path\n",
    "output_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'\n",
    "predict_dataset(input_file_path, output_file_path)\n",
    "print(f\"Predicted labels written to {output_file_path}\")\n",
    "\n",
    "\n",
    "## check accuracies\n",
    "\n",
    "import json\n",
    "\n",
    "# Function to calculate accuracy per label\n",
    "def calculate_accuracy_from_json(input_file):\n",
    "    # Load the results from the JSON file\n",
    "    with open(input_file, 'r') as file:\n",
    "        results = json.load(file)\n",
    "    \n",
    "    # Initialize counters for correct predictions and total predictions per label\n",
    "    correct_predictions = {}\n",
    "    total_predictions = {}\n",
    "    \n",
    "    # Iterate through the results and update counters\n",
    "    for result in results:\n",
    "        actual_label = result['actual_label']\n",
    "        predicted_label = result['predicted_label']\n",
    "        \n",
    "        if actual_label not in correct_predictions:\n",
    "            correct_predictions[actual_label] = 0\n",
    "            total_predictions[actual_label] = 0\n",
    "            \n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions[actual_label] += 1\n",
    "        \n",
    "        total_predictions[actual_label] += 1\n",
    "    \n",
    "    # Calculate accuracy per label\n",
    "    accuracy_per_label = {label: correct_predictions[label] / total_predictions[label] \n",
    "                          for label in total_predictions}\n",
    "    \n",
    "    return accuracy_per_label\n",
    "\n",
    "# Example usage\n",
    "input_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'   # The JSON file from the previous step\n",
    "accuracy_per_label = calculate_accuracy_from_json(input_file_path)\n",
    "\n",
    "# Display the results\n",
    "for label, accuracy in accuracy_per_label.items():\n",
    "    print(f\"Accuracy for '{label}': {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## just Secondary Model on dev_data V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels written to my_env/json_outputs/predicted_claims_secondary_model.json\n",
      "Accuracy for 'Refuted': 0.00\n",
      "Accuracy for 'Supported': 0.00\n",
      "Accuracy for 'Not Enough Evidence': 0.80\n",
      "Accuracy for 'Conflicting Evidence/Cherrypicking': 0.45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the main model and preprocessing objects\n",
    "#with open('all_data_model.pkl', 'rb') as model_file:\n",
    "    #main_rf = pickle.load(model_file)\n",
    "\n",
    "#with open('all_data_tfidf_vectorizer.pkl', 'rb') as tfidf_file:\n",
    "    #main_vectorizer = pickle.load(tfidf_file)\n",
    "\n",
    "#with open('all_data_label_map.pkl', 'rb') as label_map_file:\n",
    "    #main_label_map = pickle.load(label_map_file)\n",
    "\n",
    "# Load the secondary model and preprocessing objects\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cp_model.pkl', 'rb') as secondary_model_file:\n",
    "    secondary_rf = pickle.load(secondary_model_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cptfidf_vectorizer.pkl', 'rb') as secondary_tfidf_file:\n",
    "    secondary_vectorizer = pickle.load(secondary_tfidf_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cplabel_map.pkl', 'rb') as secondary_label_map_file:\n",
    "    secondary_label_map = pickle.load(secondary_label_map_file)\n",
    "\n",
    "# Inverse label maps\n",
    "#main_label_map_inverse = {v: k for k, v in main_label_map.items()}\n",
    "secondary_label_map_inverse = {v: k for k, v in secondary_label_map.items()}\n",
    "\n",
    "# Preprocess claims using the respective vectorizers\n",
    "def preprocess_claim(claim, vectorizer):\n",
    "    return vectorizer.transform([claim]).toarray()\n",
    "\n",
    "# First step: Classify claims using the main model\n",
    "#def classify_main(claim):\n",
    "    features = preprocess_claim(claim, main_vectorizer)\n",
    "    prediction = main_rf.predict(features)\n",
    "    probability_distribution = main_rf.predict_proba(features)\n",
    "    confidence = np.max(probability_distribution)\n",
    "    return prediction[0], confidence, probability_distribution[0]\n",
    "\n",
    "# Second step: Classify claims using the secondary model\n",
    "def classify_secondary(claim):\n",
    "    features = preprocess_claim(claim, secondary_vectorizer)\n",
    "    prediction = secondary_rf.predict(features)\n",
    "    probability_distribution = secondary_rf.predict_proba(features)\n",
    "    return prediction[0], probability_distribution[0]\n",
    "\n",
    "# Two-step classification process for a single claim\n",
    "def predict_single_claim(claim):\n",
    "    #predicted_label, confidence, probability_distribution = classify_main(claim)\n",
    "    # Use secondary model for further classification\n",
    "    predicted_label, probability_distribution = classify_secondary(claim)\n",
    "    predicted_label_name = secondary_label_map_inverse[predicted_label]\n",
    "    class_probabilities = {secondary_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "\n",
    "    return predicted_label_name, class_probabilities\n",
    "\n",
    "# Function to iterate through the dataset and predict labels\n",
    "def predict_dataset(file_path, output_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_json(file_path)\n",
    "\n",
    "    # Initialize results list\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each claim in the dataset\n",
    "    for index, row in df.iterrows():\n",
    "        claim = row['claim']\n",
    "        actual_label = row['label']\n",
    "        predicted_label, class_probabilities = predict_single_claim(claim)\n",
    "        result = {\n",
    "            'claim': claim,\n",
    "            'actual_label': actual_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'class_probabilities': class_probabilities\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Write the results to a new JSON file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(results, outfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'my_env/data/dev.json'  # Replace with your actual file path\n",
    "\n",
    "json_output_filename = \"predicted_claims_secondary_model\"\n",
    "output_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'\n",
    "predict_dataset(input_file_path, output_file_path)\n",
    "print(f\"Predicted labels written to {output_file_path}\")\n",
    "\n",
    "\n",
    "## check accuracies\n",
    "\n",
    "import json\n",
    "\n",
    "# Function to calculate accuracy per label\n",
    "def calculate_accuracy_from_json(input_file):\n",
    "    # Load the results from the JSON file\n",
    "    with open(input_file, 'r') as file:\n",
    "        results = json.load(file)\n",
    "    \n",
    "    # Initialize counters for correct predictions and total predictions per label\n",
    "    correct_predictions = {}\n",
    "    total_predictions = {}\n",
    "    \n",
    "    # Iterate through the results and update counters\n",
    "    for result in results:\n",
    "        actual_label = result['actual_label']\n",
    "        predicted_label = result['predicted_label']\n",
    "        \n",
    "        if actual_label not in correct_predictions:\n",
    "            correct_predictions[actual_label] = 0\n",
    "            total_predictions[actual_label] = 0\n",
    "            \n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions[actual_label] += 1\n",
    "        \n",
    "        total_predictions[actual_label] += 1\n",
    "    \n",
    "    # Calculate accuracy per label\n",
    "    accuracy_per_label = {label: correct_predictions[label] / total_predictions[label] \n",
    "                          for label in total_predictions}\n",
    "    \n",
    "    return accuracy_per_label\n",
    "\n",
    "# Example usage\n",
    "input_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'  # The JSON file from the previous step\n",
    "accuracy_per_label = calculate_accuracy_from_json(input_file_path)\n",
    "\n",
    "# Display the results\n",
    "for label, accuracy in accuracy_per_label.items():\n",
    "    print(f\"Accuracy for '{label}': {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## just Secondary Model on dev_data V2\n",
    "\n",
    "removed SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels written to my_env/tf-idf_data_and_models/json_outputs/predicted_claims_secondary_model_V2.json\n",
      "Accuracy for 'Refuted': 0.00\n",
      "Accuracy for 'Supported': 0.00\n",
      "Accuracy for 'Not Enough Evidence': 0.86\n",
      "Accuracy for 'Conflicting Evidence/Cherrypicking': 0.53\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the main model and preprocessing objects\n",
    "#with open('all_data_model.pkl', 'rb') as model_file:\n",
    "    #main_rf = pickle.load(model_file)\n",
    "\n",
    "#with open('all_data_tfidf_vectorizer.pkl', 'rb') as tfidf_file:\n",
    "    #main_vectorizer = pickle.load(tfidf_file)\n",
    "\n",
    "#with open('all_data_label_map.pkl', 'rb') as label_map_file:\n",
    "    #main_label_map = pickle.load(label_map_file)\n",
    "\n",
    "# Load the secondary model and preprocessing objects\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cp_model_V2.pkl', 'rb') as secondary_model_file:\n",
    "    secondary_rf = pickle.load(secondary_model_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cptfidf_vectorizer_V2.pkl', 'rb') as secondary_tfidf_file:\n",
    "    secondary_vectorizer = pickle.load(secondary_tfidf_file)\n",
    "\n",
    "with open('my_env/tf-idf_data_and_models/models/nee_cplabel_map_V2.pkl', 'rb') as secondary_label_map_file:\n",
    "    secondary_label_map = pickle.load(secondary_label_map_file)\n",
    "\n",
    "# Inverse label maps\n",
    "#main_label_map_inverse = {v: k for k, v in main_label_map.items()}\n",
    "secondary_label_map_inverse = {v: k for k, v in secondary_label_map.items()}\n",
    "\n",
    "# Preprocess claims using the respective vectorizers\n",
    "def preprocess_claim(claim, vectorizer):\n",
    "    return vectorizer.transform([claim]).toarray()\n",
    "\n",
    "# First step: Classify claims using the main model\n",
    "#def classify_main(claim):\n",
    "    features = preprocess_claim(claim, main_vectorizer)\n",
    "    prediction = main_rf.predict(features)\n",
    "    probability_distribution = main_rf.predict_proba(features)\n",
    "    confidence = np.max(probability_distribution)\n",
    "    return prediction[0], confidence, probability_distribution[0]\n",
    "\n",
    "# Second step: Classify claims using the secondary model\n",
    "def classify_secondary(claim):\n",
    "    features = preprocess_claim(claim, secondary_vectorizer)\n",
    "    prediction = secondary_rf.predict(features)\n",
    "    probability_distribution = secondary_rf.predict_proba(features)\n",
    "    return prediction[0], probability_distribution[0]\n",
    "\n",
    "# Two-step classification process for a single claim\n",
    "def predict_single_claim(claim):\n",
    "    #predicted_label, confidence, probability_distribution = classify_main(claim)\n",
    "    # Use secondary model for further classification\n",
    "    predicted_label, probability_distribution = classify_secondary(claim)\n",
    "    predicted_label_name = secondary_label_map_inverse[predicted_label]\n",
    "    class_probabilities = {secondary_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "\n",
    "    return predicted_label_name, class_probabilities\n",
    "\n",
    "# Function to iterate through the dataset and predict labels\n",
    "def predict_dataset(file_path, output_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_json(file_path)\n",
    "\n",
    "    # Initialize results list\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each claim in the dataset\n",
    "    for index, row in df.iterrows():\n",
    "        claim = row['claim']\n",
    "        actual_label = row['label']\n",
    "        predicted_label, class_probabilities = predict_single_claim(claim)\n",
    "        result = {\n",
    "            'claim': claim,\n",
    "            'actual_label': actual_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'class_probabilities': class_probabilities\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Write the results to a new JSON file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(results, outfile, indent=4)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'my_env/data/dev.json'  # Replace with your actual file path\n",
    "\n",
    "json_output_filename = \"predicted_claims_secondary_model_V2\"\n",
    "output_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'\n",
    "predict_dataset(input_file_path, output_file_path)\n",
    "print(f\"Predicted labels written to {output_file_path}\")\n",
    "\n",
    "\n",
    "## check accuracies\n",
    "\n",
    "import json\n",
    "\n",
    "# Function to calculate accuracy per label\n",
    "def calculate_accuracy_from_json(input_file):\n",
    "    # Load the results from the JSON file\n",
    "    with open(input_file, 'r') as file:\n",
    "        results = json.load(file)\n",
    "    \n",
    "    # Initialize counters for correct predictions and total predictions per label\n",
    "    correct_predictions = {}\n",
    "    total_predictions = {}\n",
    "    \n",
    "    # Iterate through the results and update counters\n",
    "    for result in results:\n",
    "        actual_label = result['actual_label']\n",
    "        predicted_label = result['predicted_label']\n",
    "        \n",
    "        if actual_label not in correct_predictions:\n",
    "            correct_predictions[actual_label] = 0\n",
    "            total_predictions[actual_label] = 0\n",
    "            \n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions[actual_label] += 1\n",
    "        \n",
    "        total_predictions[actual_label] += 1\n",
    "    \n",
    "    # Calculate accuracy per label\n",
    "    accuracy_per_label = {label: correct_predictions[label] / total_predictions[label] \n",
    "                          for label in total_predictions}\n",
    "    \n",
    "    return accuracy_per_label\n",
    "\n",
    "# Example usage\n",
    "input_file_path = f'my_env/tf-idf_data_and_models/json_outputs/{json_output_filename}.json'  # The JSON file from the previous step\n",
    "accuracy_per_label = calculate_accuracy_from_json(input_file_path)\n",
    "\n",
    "# Display the results\n",
    "for label, accuracy in accuracy_per_label.items():\n",
    "    print(f\"Accuracy for '{label}': {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy score based on labels in predicted_labels.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 'Refuted': 0.00\n",
      "Accuracy for 'Supported': 0.00\n",
      "Accuracy for 'Not Enough Evidence': 0.80\n",
      "Accuracy for 'Conflicting Evidence/Cherrypicking': 0.45\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to calculate accuracy per label\n",
    "def calculate_accuracy_from_json(input_file):\n",
    "    # Load the results from the JSON file\n",
    "    with open(input_file, 'r') as file:\n",
    "        results = json.load(file)\n",
    "    \n",
    "    # Initialize counters for correct predictions and total predictions per label\n",
    "    correct_predictions = {}\n",
    "    total_predictions = {}\n",
    "    \n",
    "    # Iterate through the results and update counters\n",
    "    for result in results:\n",
    "        actual_label = result['actual_label']\n",
    "        predicted_label = result['predicted_label']\n",
    "        \n",
    "        if actual_label not in correct_predictions:\n",
    "            correct_predictions[actual_label] = 0\n",
    "            total_predictions[actual_label] = 0\n",
    "            \n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions[actual_label] += 1\n",
    "        \n",
    "        total_predictions[actual_label] += 1\n",
    "    \n",
    "    # Calculate accuracy per label\n",
    "    accuracy_per_label = {label: correct_predictions[label] / total_predictions[label] \n",
    "                          for label in total_predictions}\n",
    "    \n",
    "    return accuracy_per_label\n",
    "filename = ''\n",
    "# Example usage\n",
    "input_file_path = f'{filename}.json'  # The JSON file from the previous step\n",
    "accuracy_per_label = calculate_accuracy_from_json(input_file_path)\n",
    "\n",
    "# Display the results\n",
    "for label, accuracy in accuracy_per_label.items():\n",
    "    print(f\"Accuracy for '{label}': {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check single claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Conflicting Evidence/Cherrypicking | Label Confidence: 0.5638047623544493\n",
      "Class Probabilities: {'Conflicting Evidence/Cherrypicking': 0.6793978972469596, 'Not Enough Evidence': 0.32060210275304035}\n"
     ]
    }
   ],
   "source": [
    "version = '_V2'\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the main model and preprocessing objects\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_model{version}.pkl', 'rb') as model_file:\n",
    "    main_rf = pickle.load(model_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_tfidf_vectorizer{version}.pkl', 'rb') as tfidf_file:\n",
    "    main_vectorizer = pickle.load(tfidf_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_label_map{version}.pkl', 'rb') as label_map_file:\n",
    "    main_label_map = pickle.load(label_map_file)\n",
    "\n",
    "# Load the secondary model and preprocessing objects\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cp_model{version}.pkl', 'rb') as secondary_model_file:\n",
    "    secondary_rf = pickle.load(secondary_model_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cptfidf_vectorizer{version}.pkl', 'rb') as secondary_tfidf_file:\n",
    "    secondary_vectorizer = pickle.load(secondary_tfidf_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cplabel_map{version}.pkl', 'rb') as secondary_label_map_file:\n",
    "    secondary_label_map = pickle.load(secondary_label_map_file)\n",
    "\n",
    "# Inverse label maps\n",
    "main_label_map_inverse = {v: k for k, v in main_label_map.items()}\n",
    "secondary_label_map_inverse = {v: k for k, v in secondary_label_map.items()}\n",
    "\n",
    "# Preprocess claims using the respective vectorizers\n",
    "def preprocess_claim(claim, vectorizer):\n",
    "    return vectorizer.transform([claim]).toarray()\n",
    "\n",
    "# First step: Classify claims using the main model\n",
    "def classify_main(claim):\n",
    "    features = preprocess_claim(claim, main_vectorizer)\n",
    "    prediction = main_rf.predict(features)\n",
    "    probability_distribution = main_rf.predict_proba(features)\n",
    "    confidence = np.max(probability_distribution)\n",
    "    return prediction[0], confidence, probability_distribution[0]\n",
    "\n",
    "# Second step: Classify claims using the secondary model\n",
    "def classify_secondary(claim):\n",
    "    features = preprocess_claim(claim, secondary_vectorizer)\n",
    "    prediction = secondary_rf.predict(features)\n",
    "    probability_distribution = secondary_rf.predict_proba(features)\n",
    "    return prediction[0], probability_distribution[0]\n",
    "\n",
    "# Two-step classification process for a single claim\n",
    "def predict_single_claim(claim):\n",
    "    predicted_label, confidence, probability_distribution = classify_main(claim)\n",
    "    \n",
    "    if main_label_map_inverse[predicted_label] in ['Supported', 'Refuted'] and confidence >= 0.65:\n",
    "        # High confidence in main model's prediction\n",
    "        predicted_label_name = main_label_map_inverse[predicted_label]\n",
    "        class_probabilities = {main_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "    else:\n",
    "        # Use secondary model for further classification\n",
    "        predicted_label, probability_distribution = classify_secondary(claim)\n",
    "        predicted_label_name = secondary_label_map_inverse[predicted_label]\n",
    "        class_probabilities = {secondary_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "\n",
    "    return predicted_label_name, class_probabilities, confidence\n",
    "\n",
    "# Example usage\n",
    "single_claim = \"Donald Trump said that $15 an hour is too much for essential workers\"\n",
    "\n",
    "predicted_label, class_probabilities, confidence = predict_single_claim(single_claim)\n",
    "print(f\"Predicted Label: {predicted_label} | Label Confidence: {confidence}\")\n",
    "print(f\"Class Probabilities: {class_probabilities}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find optimal confidence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.30, Overall Accuracy: 0.04\n",
      "  Label: Not Enough Evidence, Accuracy: 0.09\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.00\n",
      "0.04285714285714286\n",
      "0.3\n",
      "Threshold: 0.35, Overall Accuracy: 0.04\n",
      "  Label: Not Enough Evidence, Accuracy: 0.09\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.00\n",
      "Threshold: 0.40, Overall Accuracy: 0.11\n",
      "  Label: Not Enough Evidence, Accuracy: 0.23\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.00\n",
      "0.11428571428571428\n",
      "0.39999999999999997\n",
      "Threshold: 0.45, Overall Accuracy: 0.19\n",
      "  Label: Not Enough Evidence, Accuracy: 0.37\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.00\n",
      "0.18571428571428572\n",
      "0.44999999999999996\n",
      "Threshold: 0.50, Overall Accuracy: 0.25\n",
      "  Label: Not Enough Evidence, Accuracy: 0.46\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.05\n",
      "0.2548872180451128\n",
      "0.49999999999999994\n",
      "Threshold: 0.55, Overall Accuracy: 0.41\n",
      "  Label: Not Enough Evidence, Accuracy: 0.66\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.16\n",
      "0.40751879699248117\n",
      "0.5499999999999999\n",
      "Threshold: 0.60, Overall Accuracy: 0.56\n",
      "  Label: Not Enough Evidence, Accuracy: 0.77\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.34\n",
      "0.5567669172932331\n",
      "0.5999999999999999\n",
      "Threshold: 0.65, Overall Accuracy: 0.60\n",
      "  Label: Not Enough Evidence, Accuracy: 0.80\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.39\n",
      "0.5973684210526315\n",
      "0.6499999999999999\n",
      "Threshold: 0.70, Overall Accuracy: 0.64\n",
      "  Label: Not Enough Evidence, Accuracy: 0.83\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.45\n",
      "0.6379699248120301\n",
      "0.7\n",
      "Threshold: 0.75, Overall Accuracy: 0.68\n",
      "  Label: Not Enough Evidence, Accuracy: 0.86\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.50\n",
      "0.6785714285714286\n",
      "0.7499999999999999\n",
      "Threshold: 0.80, Overall Accuracy: 0.69\n",
      "  Label: Not Enough Evidence, Accuracy: 0.86\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.53\n",
      "0.6917293233082706\n",
      "0.7999999999999998\n",
      "Threshold: 0.85, Overall Accuracy: 0.69\n",
      "  Label: Not Enough Evidence, Accuracy: 0.86\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.53\n",
      "Threshold: 0.90, Overall Accuracy: 0.69\n",
      "  Label: Not Enough Evidence, Accuracy: 0.86\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.53\n",
      "Threshold: 0.95, Overall Accuracy: 0.69\n",
      "  Label: Not Enough Evidence, Accuracy: 0.86\n",
      "  Label: Conflicting Evidence/Cherrypicking, Accuracy: 0.53\n",
      "Best Confidence Threshold: 0.7999999999999998\n",
      "Best Overall Accuracy: 0.69\n",
      "Accuracy for 'Not Enough Evidence': 0.86\n",
      "Accuracy for 'Conflicting Evidence/Cherrypicking': 0.53\n"
     ]
    }
   ],
   "source": [
    "version = '_V2'\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the main model and preprocessing objects\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_model{version}.pkl', 'rb') as model_file:\n",
    "    main_rf = pickle.load(model_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_tfidf_vectorizer{version}.pkl', 'rb') as tfidf_file:\n",
    "    main_vectorizer = pickle.load(tfidf_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/all_data_label_map{version}.pkl', 'rb') as label_map_file:\n",
    "    main_label_map = pickle.load(label_map_file)\n",
    "\n",
    "# Load the secondary model and preprocessing objects\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cp_model{version}.pkl', 'rb') as secondary_model_file:\n",
    "    secondary_rf = pickle.load(secondary_model_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cptfidf_vectorizer{version}.pkl', 'rb') as secondary_tfidf_file:\n",
    "    secondary_vectorizer = pickle.load(secondary_tfidf_file)\n",
    "\n",
    "with open(f'my_env/tf-idf_data_and_models/models/nee_cplabel_map{version}.pkl', 'rb') as secondary_label_map_file:\n",
    "    secondary_label_map = pickle.load(secondary_label_map_file)\n",
    "\n",
    "# Inverse label maps\n",
    "main_label_map_inverse = {v: k for k, v in main_label_map.items()}\n",
    "secondary_label_map_inverse = {v: k for k, v in secondary_label_map.items()}\n",
    "\n",
    "# Preprocess claims using the respective vectorizers\n",
    "def preprocess_claim(claim, vectorizer):\n",
    "    return vectorizer.transform([claim]).toarray()\n",
    "\n",
    "# First step: Classify claims using the main model\n",
    "def classify_main(claim):\n",
    "    features = preprocess_claim(claim, main_vectorizer)\n",
    "    prediction = main_rf.predict(features)\n",
    "    probability_distribution = main_rf.predict_proba(features)\n",
    "    confidence = np.max(probability_distribution)\n",
    "    return prediction[0], confidence, probability_distribution[0]\n",
    "\n",
    "# Second step: Classify claims using the secondary model\n",
    "def classify_secondary(claim):\n",
    "    features = preprocess_claim(claim, secondary_vectorizer)\n",
    "    prediction = secondary_rf.predict(features)\n",
    "    probability_distribution = secondary_rf.predict_proba(features)\n",
    "    return prediction[0], probability_distribution[0]\n",
    "\n",
    "# Two-step classification process for a single claim\n",
    "def predict_single_claim(claim, confidence_threshold):\n",
    "    predicted_label, confidence, probability_distribution = classify_main(claim)\n",
    "    \n",
    "    if main_label_map_inverse[predicted_label] in ['Supported', 'Refuted'] and confidence >= confidence_threshold:\n",
    "        # High confidence in main model's prediction\n",
    "        predicted_label_name = main_label_map_inverse[predicted_label]\n",
    "        class_probabilities = {main_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "    else:\n",
    "        # Use secondary model for further classification\n",
    "        predicted_label, probability_distribution = classify_secondary(claim)\n",
    "        predicted_label_name = secondary_label_map_inverse[predicted_label]\n",
    "        class_probabilities = {secondary_label_map_inverse[i]: prob for i, prob in enumerate(probability_distribution)}\n",
    "\n",
    "    return predicted_label_name, class_probabilities\n",
    "\n",
    "# Function to iterate through the dataset and predict labels\n",
    "def predict_dataset(file_path, output_file, confidence_threshold):\n",
    "    # Load the dataset\n",
    "    df = pd.read_json(file_path)\n",
    "\n",
    "    # Initialize results list\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each claim in the dataset\n",
    "    for index, row in df.iterrows():\n",
    "        claim = row['claim']\n",
    "        actual_label = row['label']\n",
    "        predicted_label, class_probabilities = predict_single_claim(claim, confidence_threshold)\n",
    "        result = {\n",
    "            'claim': claim,\n",
    "            'actual_label': actual_label,\n",
    "            'predicted_label': predicted_label,\n",
    "            'class_probabilities': class_probabilities\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Write the results to a new JSON file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(results, outfile, indent=4)\n",
    "\n",
    "# Function to calculate accuracy per label\n",
    "def calculate_accuracy_from_json(input_file):\n",
    "    # Load the results from the JSON file\n",
    "    with open(input_file, 'r') as file:\n",
    "        results = json.load(file)\n",
    "    \n",
    "    # Initialize counters for correct predictions and total predictions per label\n",
    "    correct_predictions = {}\n",
    "    total_predictions = {}\n",
    "    \n",
    "    # Iterate through the results and update counters\n",
    "    for result in results:\n",
    "        actual_label = result['actual_label']\n",
    "        predicted_label = result['predicted_label']\n",
    "        \n",
    "        if actual_label not in correct_predictions:\n",
    "            correct_predictions[actual_label] = 0\n",
    "            total_predictions[actual_label] = 0\n",
    "            \n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions[actual_label] += 1\n",
    "        \n",
    "        total_predictions[actual_label] += 1\n",
    "    \n",
    "    # Calculate accuracy per label\n",
    "    accuracy_per_label = {label: correct_predictions[label] / total_predictions[label] \n",
    "                          for label in total_predictions}\n",
    "    \n",
    "    return accuracy_per_label\n",
    "\n",
    "# Function to find the optimal confidence threshold\n",
    "def find_optimal_threshold(input_file, output_file):\n",
    "    thresholds = np.arange(0.3, 1.0, 0.05)\n",
    "    best_threshold = 0.3\n",
    "    best_accuracy = 0.0\n",
    "    best_accuracy_per_label = {}\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        predict_dataset(input_file, output_file, threshold)\n",
    "        accuracy_per_label = calculate_accuracy_from_json(output_file)\n",
    "        overall_accuracy = sum(accuracy_per_label.values()) / len(accuracy_per_label)\n",
    "        \n",
    "        print(f\"Threshold: {threshold:.2f}, Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "        for label, accuracy in accuracy_per_label.items():\n",
    "            print(f\"  Label: {label}, Accuracy: {accuracy:.2f}\")\n",
    "            \n",
    "        if overall_accuracy > best_accuracy:\n",
    "            best_accuracy = overall_accuracy\n",
    "            print(best_accuracy)\n",
    "            best_threshold = threshold\n",
    "            print(best_threshold)\n",
    "            best_accuracy_per_label = accuracy_per_label\n",
    "    \n",
    "    return best_threshold, best_accuracy, best_accuracy_per_label\n",
    "\n",
    "# Example usage to find the optimal threshold\n",
    "input_file_path = 'my_env/data/not_enough_info_from_dev.json'  # Replace with your actual file path\n",
    "output_file_path = f'find_optimal_confidence{version}.json'\n",
    "\n",
    "best_threshold, best_accuracy, best_accuracy_per_label = find_optimal_threshold(input_file_path, output_file_path)\n",
    "\n",
    "print(f\"Best Confidence Threshold: {best_threshold}\")\n",
    "print(f\"Best Overall Accuracy: {best_accuracy:.2f}\")\n",
    "for label, accuracy in best_accuracy_per_label.items():\n",
    "    print(f\"Accuracy for '{label}': {accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
