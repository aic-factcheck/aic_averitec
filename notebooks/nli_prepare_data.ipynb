{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for NLI finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "dotenv_path = Path('aic_averitec/.env')\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "DATASTORE_PATH = os.environ.get(\"DATASTORE_PATH\")\n",
    "DATASET_PATH = os.environ.get(\"DATASET_PATH\")\n",
    "MODELS_PATH = os.environ.get(\"MODELS_PATH\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DEV_PATH = str(os.path.join(DATASET_PATH, 'dev.json'))\n",
    "TRAIN_PATH = str(os.path.join(DATASET_PATH, 'train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim': 'Hunter Biden had no experience in Ukraine or in the energy sector when he joined the board of Burisma.', 'required_reannotation': False, 'label': 'Supported', 'justification': 'No former experience stated.', 'claim_date': '25-8-2020', 'speaker': 'Pam Bondi', 'original_claim_url': None, 'fact_checking_article': 'https://web.archive.org/web/20210111003633/https://www.politifact.com/article/2020/aug/26/fact-checking-second-night-2020-rnc/', 'reporting_source': 'Speech at The Republican National Convention', 'location_ISO_code': 'US', 'claim_types': ['Position Statement'], 'fact_checking_strategies': ['Written Evidence'], 'questions': [{'question': 'Did Hunter Biden have any experience in the energy sector at the time he joined the board of the  Burisma energy company in 2014', 'answers': [{'answer': 'No', 'answer_type': 'Boolean', 'source_url': 'https://en.wikipedia.org/wiki/Hunter_Biden', 'source_medium': 'Web text', 'boolean_explanation': \"Hunter bidens previous career history does not include work for energy company's.\", 'cached_source_url': 'https://web.archive.org/web/20230323135844/https://en.wikipedia.org/wiki/Hunter_Biden'}]}, {'question': 'Did Hunter Biden have any experience in Ukraine at the time he joined the board of the  Burisma energy company in 2014', 'answers': [{'answer': 'No', 'answer_type': 'Boolean', 'source_url': 'https://en.wikipedia.org/wiki/Hunter_Biden', 'source_medium': 'Web text', 'boolean_explanation': \"Hunter Bidens previous career history does not include working with Ukrainian company's.\", 'cached_source_url': 'https://web.archive.org/web/20230323135844/https://en.wikipedia.org/wiki/Hunter_Biden'}]}], 'cached_original_claim_url': None}\n",
      "3068\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#load originial data\n",
    "with open(TRAIN_PATH, \"r\") as f:\n",
    "    training_data = json.load(f)\n",
    "\n",
    "print(training_data[0])\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_data(input_data):\n",
    "    result_data = []\n",
    "    for data in input_data:\n",
    "        for question in data[\"questions\"]:\n",
    "            for answer in question[\"answers\"]:\n",
    "                #discard conflictign evidence/cherrypicking\n",
    "                if data[\"label\"] != \"Conflicting Evidence/Cherrypicking\":\n",
    "                    if answer[\"answer_type\"] == \"Boolean\":\n",
    "                        result_data.append({\"claim\": data[\"claim\"], \"evidence\": answer[\"boolean_explanation\"], \"label\": data[\"label\"]})\n",
    "                    elif answer[\"answer_type\"] == \"Unanswerable\":\n",
    "                        pass\n",
    "                    else:\n",
    "                        result_data.append({\"claim\": data[\"claim\"], \"evidence\": answer[\"answer\"], \"label\": data[\"label\"]})\n",
    "    \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim': 'Hunter Biden had no experience in Ukraine or in the energy sector when he joined the board of Burisma.', 'evidence': \"Hunter bidens previous career history does not include work for energy company's.\", 'label': 'Supported'}\n",
      "7321\n"
     ]
    }
   ],
   "source": [
    "#extract the text and the label to json\n",
    "\n",
    "result_data = get_result_data(training_data)\n",
    "\n",
    "print(result_data[0])\n",
    "print(len(result_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_jsonl(data, dataset_name):\n",
    "    with open(os.path.join(DATASET_PATH, dataset_name), \"w\") as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_jsonl(result_data, \"train_nli_a.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QA nli data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_data_qa(input_data):\n",
    "    result_data_qa = []\n",
    "    for data in input_data:\n",
    "        for question in data[\"questions\"]:\n",
    "            for answer in question[\"answers\"]:\n",
    "                #discard conflictign evidence/cherrypicking\n",
    "                if data[\"label\"] != \"Conflicting Evidence/Cherrypicking\":\n",
    "                    if answer[\"answer_type\"] == \"Boolean\":\n",
    "                        result_data_qa.append({\"claim\": data[\"claim\"], \"evidence\": question[\"question\"] + \" \" + answer[\"answer\"] + \" \" +  answer[\"boolean_explanation\"], \"label\": data[\"label\"]})\n",
    "                    else:\n",
    "                        result_data_qa.append({\"claim\": data[\"claim\"], \"evidence\": question[\"question\"] + \" \" + answer[\"answer\"], \"label\": data[\"label\"]})\n",
    "\n",
    "    return result_data_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim': 'Hunter Biden had no experience in Ukraine or in the energy sector when he joined the board of Burisma.', 'evidence': \"Did Hunter Biden have any experience in the energy sector at the time he joined the board of the  Burisma energy company in 2014 No Hunter bidens previous career history does not include work for energy company's.\", 'label': 'Supported'}\n",
      "7688\n"
     ]
    }
   ],
   "source": [
    "#extract the text and the label to json\n",
    "\n",
    "result_data_qa = get_result_data_qa(training_data)\n",
    "\n",
    "print(result_data_qa[0])\n",
    "print(len(result_data_qa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_jsonl(result_data_qa, \"train_nli_qa.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 labels, concat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_data_4concat(input_data):\n",
    "    result_data_qa = []\n",
    "    for data in input_data:\n",
    "        evidence:str = \"\"\n",
    "        for question in data[\"questions\"]:\n",
    "            for answer in question[\"answers\"]:\n",
    "                if answer[\"answer_type\"] == \"Boolean\":\n",
    "                    evidence += question[\"question\"] + \" \" + answer[\"answer\"] + \" \" +  answer[\"boolean_explanation\"] + \" \"\n",
    "                else:\n",
    "                    evidence += question[\"question\"] + \" \" + answer[\"answer\"] + \" \"\n",
    "        \n",
    "        #evidence without last space\n",
    "        result_data_qa.append({\"claim\": data[\"claim\"], \"evidence\": evidence[:-1], \"label\": data[\"label\"]})\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "    return result_data_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim': 'Hunter Biden had no experience in Ukraine or in the energy sector when he joined the board of Burisma.', 'evidence': \"Did Hunter Biden have any experience in the energy sector at the time he joined the board of the  Burisma energy company in 2014 No Hunter bidens previous career history does not include work for energy company's. Did Hunter Biden have any experience in Ukraine at the time he joined the board of the  Burisma energy company in 2014 No Hunter Bidens previous career history does not include working with Ukrainian company's.\", 'label': 'Supported'}\n",
      "3068\n"
     ]
    }
   ],
   "source": [
    "result_data_4concat = get_result_data_4concat(training_data)\n",
    "\n",
    "print(result_data_4concat[0])\n",
    "print(len(result_data_4concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_jsonl(result_data_4concat, \"train_nli_4concat.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 labels concat in all orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def get_result_data_4concat_all_orders(input_data):\n",
    "    result_data_qa = []\n",
    "    for data in input_data:\n",
    "        \n",
    "\n",
    "        qas = [(q[\"question\"],a[\"answer\"] if a[\"answer_type\"] != \"Boolean\" else a[\"answer\"] + \" \"+ a[\"boolean_explanation\"]) for q in data[\"questions\"] for a in q[\"answers\"]]\n",
    "        \n",
    "        for i in range(min(len(qas), 10)):\n",
    "            random.shuffle(qas)\n",
    "            perm = qas\n",
    "            evidence:str = \"\"\n",
    "            for qa in perm:\n",
    "                evidence += qa[0] + \" \" + qa[1] + \" \"\n",
    "\n",
    "            result_data_qa.append({\"claim\": data[\"claim\"], \"evidence\": evidence[:-1], \"label\": data[\"label\"]})\n",
    "            \n",
    "\n",
    "    return result_data_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim': 'Biden will take away the Second Amendment.', 'evidence': 'Has Joe Biden\\'s plan for gun regulation and control infringed on the second amendment Biden’s plan to end gun violence says \"It’s within our grasp to end our gun violence epidemic and respect the Second Amendment, which is limited,\"', 'label': 'Refuted'}\n",
      "8451\n"
     ]
    }
   ],
   "source": [
    "result_data_4_concat_all_orders = get_result_data_4concat_all_orders(training_data)\n",
    "\n",
    "print(result_data_4_concat_all_orders[20])\n",
    "print(len(result_data_4_concat_all_orders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_jsonl(result_data_4_concat_all_orders, \"train_nli_4concat_all_orders.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 labesl concat with [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_data_4_sep(input_data):\n",
    "    result_data_qa = []\n",
    "    for data in input_data:\n",
    "        evidence:str = \"\"\n",
    "        for question in data[\"questions\"]:\n",
    "            for answer in question[\"answers\"]:\n",
    "                if answer[\"answer_type\"] == \"Boolean\":\n",
    "                    evidence += question[\"question\"] + \" \" + answer[\"answer\"] + \" \" +  answer[\"boolean_explanation\"] + \"[SEP]\"\n",
    "                else:\n",
    "                    evidence += question[\"question\"] + \" \" + answer[\"answer\"] + \"[SEP]\"\n",
    "        \n",
    "        #evidence without last space\n",
    "        result_data_qa.append({\"claim\": data[\"claim\"], \"evidence\": evidence[:-5], \"label\": data[\"label\"]})\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "    return result_data_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim': 'Facebook deleted a photo of Melania Trump with her sister and mother.', 'evidence': 'Does the photo show Melania with her sister and her mother? it shows Melania, her sister and audrey gruss (not Melanias mother)[SEP]Was this image removed by facebook? No the photo was not removed from Facebook', 'label': 'Refuted'}\n",
      "3068\n"
     ]
    }
   ],
   "source": [
    "result_data_4_sep = get_result_data_4_sep(training_data)\n",
    "\n",
    "print(result_data_4_sep[100])\n",
    "print(len(result_data_4_sep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_jsonl(result_data_4_sep, \"train_nli_4sep.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bin cherrypicking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_result_data_bin_concat(input_data):\n",
    "    result_data_qa = []\n",
    "    for data in input_data:\n",
    "        evidence:str = \"\"\n",
    "        for question in data[\"questions\"]:\n",
    "            for answer in question[\"answers\"]:\n",
    "                if answer[\"answer_type\"] == \"Boolean\":\n",
    "                    evidence += question[\"question\"] + \" \" + answer[\"answer\"] + \" \" +  answer[\"boolean_explanation\"] + \" \"\n",
    "                else:\n",
    "                    evidence += question[\"question\"] + \" \" + answer[\"answer\"] + \" \"\n",
    "        \n",
    "        #evidence without last space\n",
    "        label = 1 if data[\"label\"] == \"Conflicting Evidence/Cherrypicking\" else 0\n",
    "        result_data_qa.append({\"claim\": data[\"claim\"], \"evidence\": evidence[:-1], \"label\": label})\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "    return result_data_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim': 'Hunter Biden had no experience in Ukraine or in the energy sector when he joined the board of Burisma.', 'evidence': \"Did Hunter Biden have any experience in the energy sector at the time he joined the board of the  Burisma energy company in 2014 No Hunter bidens previous career history does not include work for energy company's. Did Hunter Biden have any experience in Ukraine at the time he joined the board of the  Burisma energy company in 2014 No Hunter Bidens previous career history does not include working with Ukrainian company's.\", 'label': 0}\n",
      "3068\n"
     ]
    }
   ],
   "source": [
    "result_data_bin_concat = get_result_data_bin_concat(training_data)\n",
    "\n",
    "print(result_data_bin_concat[0])\n",
    "print(len(result_data_bin_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_jsonl(result_data_bin_concat, \"train_nli_bin_concat.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [dat[\"label\"] for dat in result_data]\n",
    "labels_qa = [dat[\"label\"] for dat in result_data_qa]\n",
    "labels_4concat = [dat[\"label\"] for dat in result_data_4concat]\n",
    "labels_bin_concat = [dat[\"label\"] for dat in result_data_bin_concat]\n",
    "labels_4sep = [dat[\"label\"] for dat in result_data_4_sep]\n",
    "labels_4_concat_all_orders = [dat[\"label\"] for dat in result_data_4_concat_all_orders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Not Enough Evidence': 626, 'Refuted': 4471, 'Supported': 2224}\n",
      "{'Not Enough Evidence': 839, 'Refuted': 4599, 'Supported': 2250}\n",
      "{'Conflicting Evidence/Cherrypicking': 195, 'Not Enough Evidence': 282, 'Refuted': 1742, 'Supported': 849}\n",
      "{0: 2873, 1: 195}\n",
      "{'Conflicting Evidence/Cherrypicking': 195, 'Not Enough Evidence': 282, 'Refuted': 1742, 'Supported': 849}\n",
      "{'Conflicting Evidence/Cherrypicking': 789, 'Not Enough Evidence': 839, 'Refuted': 4586, 'Supported': 2237}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(labels_qa, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(labels_4concat, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(labels_bin_concat, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(labels_4sep, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(labels_4_concat_all_orders, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same for dev data\n",
    "with open(DEV_PATH, \"r\") as f:\n",
    "    dev_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = get_result_data(dev_data)\n",
    "result_data_qa = get_result_data_qa(dev_data)\n",
    "result_data_4concat = get_result_data_4concat(dev_data)\n",
    "result_data_bin_concat = get_result_data_bin_concat(dev_data)\n",
    "result_data_4sep = get_result_data_4_sep(dev_data)\n",
    "result_data_4_concat_all_orders = get_result_data_4concat_all_orders(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_jsonl(result_data, \"dev_nli_a.jsonl\")\n",
    "save_to_jsonl(result_data_qa, \"dev_nli_qa.jsonl\")\n",
    "save_to_jsonl(result_data_4concat, \"dev_nli_4concat.jsonl\")\n",
    "save_to_jsonl(result_data_bin_concat, \"dev_nli_bin_concat.jsonl\")\n",
    "save_to_jsonl(result_data_4sep, \"dev_nli_4sep.jsonl\")\n",
    "save_to_jsonl(result_data_4_concat_all_orders, \"dev_nli_4concat_all_orders.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try loading with HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a47dfe90bf4a6aa9eac3b3ae2b8441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b529f50b9d4a9192f30be1a32c256d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['claim', 'evidence', 'label'],\n",
      "        num_rows: 7321\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['claim', 'evidence', 'label'],\n",
      "        num_rows: 1227\n",
      "    })\n",
      "})\n",
      "{'claim': 'Hunter Biden had no experience in Ukraine or in the energy sector when he joined the board of Burisma.', 'evidence': \"Hunter bidens previous career history does not include work for energy company's.\", 'label': 'Supported'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files = {\"train\": os.path.join(DATASET_PATH, \"train_nli_a.jsonl\"), \"dev\": os.path.join(DATASET_PATH, \"dev_nli_a.jsonl\")})\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlynatom/venvs/py3.10.4/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_id = \"microsoft/deberta-v3-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b585c9994f486da659ce5d113216a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e98354a4f79481896b4a0f2b79dcb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1227 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    example = tokenizer(examples[\"claim\"], examples[\"evidence\"], truncation=True)\n",
    "    example[\"label\"] = examples[\"label\"]\n",
    "    return example\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'evidence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 7321\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['claim', 'evidence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1227\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
